{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64311526-10f7-4e73-bedc-743a895080af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e08aec3e-6e70-40a9-938f-47078ca9f9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b1c3c8e612475cac4ae04b42bceaef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/87.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ranea\\anaconda3\\envs\\nlpenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ranea\\.cache\\huggingface\\hub\\models--google--pegasus-xsum. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\ranea\\anaconda3\\envs\\nlpenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6828fbdeaead403f9cf1b95e196fa564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647a3f570b844bb4a81f226563402dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372d731e6df2465b8d8d1d7760b8e07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.52M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4aaf4050574229bec60a6dd757d4b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained (\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fc3d99f-9486-4f24-ac9c-eee7ae36f50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11fb3bf4b2964e66a8de38a7453592ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e71f790ff8472787148e97b0588904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/259 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = PegasusForConditionalGeneration.from_pretrained (\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfbab041-8e53-4d50-8df2-97778e56fa1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 8087,  9688,   930,  6910,   554,   184,   123,   216, 13501,  9688,\n",
       "           930,  6910,   554,   108,   150,   177, 10130,   861,   120,   137,\n",
       "           870,   482,  2327,   108,  1942,   108,   111,  1352,   115,   440,\n",
       "           166,   107,  9688,   930,  6910,   554,  5883,   554,   227,   118,\n",
       "           185, 12008,  4103,  6169,   117,   114,   863,  1239,   249,   154,\n",
       "           710,   883,   121, 24146,  4506,   560,  1418, 11517,   130,  3196,\n",
       "           189,  1852,   113,  1352,   108,  2327,   108,   805,   108,   111,\n",
       "           545,   111, 11457,   189,  1852,   113,  1352,   108,  2327,   108,\n",
       "           111,   805, 15487,   107,   168,   137,  2847,   112,  2327, 12212,\n",
       "           115,   130,   332,   130, 41140, 49862,   108,   122,   142,  1077,\n",
       "           113, 17413, 49862,   108,   162,   117,   984,   112,   883,  1407,\n",
       "           166,   741,  9553,   116,   115,   114,   177,  1437,   158,   115,\n",
       "           114,  2594,   107,   168,  3637,  9688,   930,  6910, 14739,   637,\n",
       "           124,  1352,   115,  1188,   111,   929,   108,   122,  1225,  2757,\n",
       "           124,  1352,   115,   609,   121, 14157,  4482,   108,   277,   163,\n",
       "           270,   249,  2347,   111,  4567,  4741,   115,   109,  5080,   107,\n",
       "          9688,   930,  6910,   554,   117,   704,   340,   134,  1942,   111,\n",
       "          2327,  1301,  1711,   112,  1385,  1581,   107,  7621,   112,  9688,\n",
       "           930,  6910,   554,   108,   119,   256,   207,  9204, 10688,   112,\n",
       "          1002,   112,  9327,  1064, 12943,   122,  1095, 40546,   113, 21690,\n",
       "          2286,   143,  1064, 12943,   121, 18476,   158,   111, 34423,  2286,\n",
       "           143,  1064, 12943, 51549,   124,  1077,   107,   413,  1433,   136,\n",
       "           108,  9204, 10688,   117,   114,  7684,   113,   339,  1910,  1581,\n",
       "           151,   156,   586,   861, 62206,   116,  2327,   112,  1352,   108,\n",
       "          9688,   930,   121, 18476,   132,  9688,   930,  6910,   839,   115,\n",
       "          1352,   111, 15487,  1352,   108,   111,   114,   776,   586,   861,\n",
       "         18401,   120,  1352,   247,   112,  2327,   107,   182,   366,   495,\n",
       "           120,   109,   674,  1116,   113,  3941,   108,  9688,   930,  6910,\n",
       "           108, 14358,   114,   367,   113,   257,   560,  1418,   137,   123,\n",
       "           144,  1072,  6607,  4104,   108,  1079,  4155,   108,   132,  1688,\n",
       "         19937,   108,   111,   126,   137,   123,   144,  2940, 11366,   108,\n",
       "          4924,   108,   132,  3520,  8179,   107,   441,  9688,   930,  6910,\n",
       "           554,   108,   145,  2492,   114,   612,   177,   861,   370,   121,\n",
       "           497,   121,  2797,   482,  1352,   108,  1942,   108,   111,  2327,\n",
       "           108,  2050,   120,   149, 12212,   111, 15487,   127,  4972,   141,\n",
       "           109,   310, 14849,   952,   107,  2110,  9688,   930,  6910,   554,\n",
       "           117,   150,   211,   861,  6839,   149,   113,   219, 27291,   108,\n",
       "           145,   127,   309,   188, 20981,   109,  1494,   113,  3976,   180,\n",
       "           109,   861,   137,   171,   111,   203,  6244,   107,   110,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Hello GPT-4o\n",
    "We’re announcing GPT-4o, our new flagship model that can reason across audio, vision, and text in real time.\n",
    "GPT-4o (“o” for “omni”) is a step towards much more natural human-computer interaction—it accepts as input any combination of text, \n",
    "audio, image, and video and generates any combination of text, audio, and image outputs. It can respond to audio inputs in as little as\n",
    "232 milliseconds, with an average of 320 milliseconds, which is similar to human response time(opens in a new window) in a conversation.\n",
    "It matches GPT-4 Turbo performance on text in English and code, with significant improvement on text in non-English languages, \n",
    "while also being much faster and 50% cheaper in the API. GPT-4o is especially better at vision and audio understanding compared to existing models.\n",
    "Prior to GPT-4o, you could use Voice Mode to talk to ChatGPT with latencies of 2.8 seconds (GPT-3.5) and 5.4 seconds (GPT-4) on average. \n",
    "To achieve this, Voice Mode is a pipeline of three separate models: one simple model transcribes audio to text, GPT-3.5 or GPT-4 takes in \n",
    "text and outputs text, and a third simple model converts that text back to audio. This process means that the main source of intelligence,\n",
    "GPT-4, loses a lot of information—it can’t directly observe tone, multiple speakers, or background noises, and it can’t output laughter, singing, or express emotion.\n",
    "With GPT-4o, we trained a single new model end-to-end across text, vision, and audio, meaning that all inputs and outputs are processed by \n",
    "the same neural network. Because GPT-4o is our first model combining all of these modalities, we are still just scratching the surface of \n",
    "exploring what the model can do and its limitations.\n",
    "\"\"\"\n",
    "\n",
    "tokens = tokenizer (text, truncation= True, padding=\"longest\", return_tensors=\"pt\") \n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "052271ad-b508-404a-8db9-46fc369e5763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 8087,  9688,   930,  6910,   554,   184,   123,   216, 13501,  9688,\n",
       "            930,  6910,   554,   108,   150,   177, 10130,   861,   120,   137,\n",
       "            870,   482,  2327,   108,  1942,   108,   111,  1352,   115,   440,\n",
       "            166,   107,  9688,   930,  6910,   554,  5883,   554,   227,   118,\n",
       "            185, 12008,  4103,  6169,   117,   114,   863,  1239,   249,   154,\n",
       "            710,   883,   121, 24146,  4506,   560,  1418, 11517,   130,  3196,\n",
       "            189,  1852,   113,  1352,   108,  2327,   108,   805,   108,   111,\n",
       "            545,   111, 11457,   189,  1852,   113,  1352,   108,  2327,   108,\n",
       "            111,   805, 15487,   107,   168,   137,  2847,   112,  2327, 12212,\n",
       "            115,   130,   332,   130, 41140, 49862,   108,   122,   142,  1077,\n",
       "            113, 17413, 49862,   108,   162,   117,   984,   112,   883,  1407,\n",
       "            166,   741,  9553,   116,   115,   114,   177,  1437,   158,   115,\n",
       "            114,  2594,   107,   168,  3637,  9688,   930,  6910, 14739,   637,\n",
       "            124,  1352,   115,  1188,   111,   929,   108,   122,  1225,  2757,\n",
       "            124,  1352,   115,   609,   121, 14157,  4482,   108,   277,   163,\n",
       "            270,   249,  2347,   111,  4567,  4741,   115,   109,  5080,   107,\n",
       "           9688,   930,  6910,   554,   117,   704,   340,   134,  1942,   111,\n",
       "           2327,  1301,  1711,   112,  1385,  1581,   107,  7621,   112,  9688,\n",
       "            930,  6910,   554,   108,   119,   256,   207,  9204, 10688,   112,\n",
       "           1002,   112,  9327,  1064, 12943,   122,  1095, 40546,   113, 21690,\n",
       "           2286,   143,  1064, 12943,   121, 18476,   158,   111, 34423,  2286,\n",
       "            143,  1064, 12943, 51549,   124,  1077,   107,   413,  1433,   136,\n",
       "            108,  9204, 10688,   117,   114,  7684,   113,   339,  1910,  1581,\n",
       "            151,   156,   586,   861, 62206,   116,  2327,   112,  1352,   108,\n",
       "           9688,   930,   121, 18476,   132,  9688,   930,  6910,   839,   115,\n",
       "           1352,   111, 15487,  1352,   108,   111,   114,   776,   586,   861,\n",
       "          18401,   120,  1352,   247,   112,  2327,   107,   182,   366,   495,\n",
       "            120,   109,   674,  1116,   113,  3941,   108,  9688,   930,  6910,\n",
       "            108, 14358,   114,   367,   113,   257,   560,  1418,   137,   123,\n",
       "            144,  1072,  6607,  4104,   108,  1079,  4155,   108,   132,  1688,\n",
       "          19937,   108,   111,   126,   137,   123,   144,  2940, 11366,   108,\n",
       "           4924,   108,   132,  3520,  8179,   107,   441,  9688,   930,  6910,\n",
       "            554,   108,   145,  2492,   114,   612,   177,   861,   370,   121,\n",
       "            497,   121,  2797,   482,  1352,   108,  1942,   108,   111,  2327,\n",
       "            108,  2050,   120,   149, 12212,   111, 15487,   127,  4972,   141,\n",
       "            109,   310, 14849,   952,   107,  2110,  9688,   930,  6910,   554,\n",
       "            117,   150,   211,   861,  6839,   149,   113,   219, 27291,   108,\n",
       "            145,   127,   309,   188, 20981,   109,  1494,   113,  3976,   180,\n",
       "            109,   861,   137,   171,   111,   203,  6244,   107,   110,     1]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summarize\n",
    "summary= model.generate (**tokens)\n",
    "{**tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4981ccde-451d-42a5-b54f-74845e99e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary in tokens\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
